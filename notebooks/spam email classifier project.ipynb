{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691c5a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import digits\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966c5b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStem(review):\n",
    "    review = str(review)\n",
    "    review = review.lower()\n",
    "    tokens = tokenizer.tokenize(review) # breaking into small words\n",
    "    removed_stopwords = [w for w in tokens if w not in sw]\n",
    "    stemmed_words = [ps.stem(token) for token in removed_stopwords]\n",
    "    clean_review = ' '.join(stemmed_words)\n",
    "    table = clean_review.maketrans(\"\", \"\", digits)\n",
    "    clean_review = clean_review.translate(table)\n",
    "\n",
    "    return clean_review\n",
    "# get a clean document\n",
    "def getDoc(document):\n",
    "    d = []\n",
    "    for doc in document:\n",
    "        d.append(getStem(doc))\n",
    "    return d\n",
    "\n",
    "tokenizer=RegexpTokenizer(\"\\w+\")\n",
    "sw = set(stopwords.words(\"english\"))\n",
    "ps=PorterStemmer()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b546252d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boat still mom check yo half nake</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bank granit issu strong buy explos pick member...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r give second chanc rahul dengra</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>play smash bro lt gt religi</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>privat  account statement  show  un redeem poi...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>came hostel go sleep plz call class hrishi</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>sorri call later</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>prabha soryda reali frm heart sori</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>nt joke serious told</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>work go min</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3569 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0    v1\n",
       "0                     boat still mom check yo half nake   ham\n",
       "1     bank granit issu strong buy explos pick member...   ham\n",
       "2                      r give second chanc rahul dengra  spam\n",
       "3                           play smash bro lt gt religi   ham\n",
       "4     privat  account statement  show  un redeem poi...   ham\n",
       "...                                                 ...   ...\n",
       "4452         came hostel go sleep plz call class hrishi   ham\n",
       "4453                                   sorri call later   ham\n",
       "4454                 prabha soryda reali frm heart sori   ham\n",
       "4455                               nt joke serious told   ham\n",
       "4456                                        work go min   ham\n",
       "\n",
       "[3569 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('D:/end to end implemention machine learning/notebooks/data/spamsms.csv', encoding='ISO-8859-1')\n",
    "data= data[[\"v1\",\"v2\"]]\n",
    "\n",
    "y = data[\"v1\"]\n",
    "X = data[\"v2\"]\n",
    "\n",
    "X = getDoc(X)\n",
    "X\n",
    "\n",
    "X_train ,X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.20)\n",
    "\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "X_train = pd.concat([X_train, y_train], axis=1)\n",
    "X_test = pd.concat([X_test, y_test])\n",
    "X_train.dropna(inplace=True)\n",
    "X_test.dropna(inplace=True)\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d15cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd1f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ak064\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"D:/end to end implemention machine learning/notebooks/data/train.csv\")\n",
    "X_test = pd.read_csv(\"D:/end to end implemention machine learning/notebooks/data/train.csv\")\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X_train.rename(columns={\"0\":\"text\",\"v1\":\"label\"}, inplace=True)\n",
    "X_train = X_train[[\"text\", \"label\"]]\n",
    "# xtrain ready\n",
    "X = X_train[[\"text\"]] \n",
    "y = X_train[[\"label\"]] \n",
    "\n",
    "X = getDoc(X_train[\"text\"])\n",
    "new_x = cv.fit_transform(X)\n",
    "X_train = new_x.toarray()\n",
    "\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y)\n",
    "\n",
    "#  model training\n",
    "mode = model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5552d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 1]\n",
    "y = data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce917d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "498c72f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tokenizer = RegexpTokenizer('\\w+')\n",
    "# sw = set(stopwords.words('english'))\n",
    "# ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a50cd7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_sen(review):\n",
    "#     review = review.lower()\n",
    "#     token = tokenizer.tokenize(review)\n",
    "#     remove_words = [w for w in token if w not in sw]\n",
    "#     stemming_words = [ps.stem(token) for token in remove_words]\n",
    "#     clean_words = ' '.join(stemming_words)\n",
    "#     return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0035eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_doc(document):\n",
    "#     a=[]\n",
    "#     for doc in document:\n",
    "#         a.append(remove_sen(doc))\n",
    "#     return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a8fbf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = get_doc(X)\n",
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "869517e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0b8f2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc084ae9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m check\u001b[39m=\u001b[39mgetDoc(X)\n\u001b[0;32m      2\u001b[0m check[:\u001b[39m10\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "check=getDoc(X)\n",
    "check[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e1d6b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79783957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x7284 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 118 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cv.fit_transform(check)\n",
    "model[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3bebdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=model.toarray()\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fef06728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94cb9eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43402100",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnb= MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca75e53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77cba81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnb.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec0e2251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9809679173463839"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e479674",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes =[\n",
    "    \n",
    "\"\"\"Free Data Science Masterclass starting in 30 minutes...click on the button below at 8 pm sharp to join with zoom app:\n",
    "\n",
    "P.S. If you already attended then you don't need to attend again!\"\"\",\n",
    "    \"\"\"Hi Aman, Let's keep the trend going and have ourselves a trends-day Wednesday! Come explore what we have in store for Day 8: 21 Days Challenge: Day 8 Problem of the Day\n",
    "Best Performers of Day 7 of 21 Days Challenge\"\"\",\n",
    "    \n",
    "\"\"\"Free Data Science Masterclass starting in 30 minutes...click on the button below at 8 pm sharp to join with zoom app:\n",
    "\n",
    "P.S. If you already attended then you don't need to attend again!\"\"\",\n",
    "\"\"\"Hi Aman,\n",
    "Some nice music is on and we're about to start!\n",
    "Seats are limited, so make sure you join immediately by clicking on the button below!\"\"\",\n",
    "    \n",
    "\"\"\"Hi Aman kumar,\n",
    "Did you know about the new cut-off score for the Relevel Test? Now, you just have to score 500+ to qualify the Test and start interviewing with some of India’s finest companies.\n",
    "The new cut-off increases your chance to ace the Test. So, make the most of this opportunity by booking your Relevel Test today.\n",
    "Take the Test today, score 500+ and get ready to be hired within 15 days or less.\"\"\",\n",
    "    \"\"\"\n",
    "    Hi Kunal,\n",
    "We invite you to participate in MishMash - India’s largest online diversity hackathon. \n",
    "The hackathon is a Skillenza initiative and sponsored by Microsoft, Unity, Unilever, Gojek, Rocketium and Jharkhand Government. \n",
    "We have a special theme for you - Deep Tech/Machine Learning - sponsored by Unilever, which will be perfect for you.\n",
    "    \"\"\",\n",
    "    \"\"\"Join us today at 12:00 PM ET / 16:00 UTC for a Red Hat DevNation tech talk on AWS Lambda and serverless Java with Bill Burke.\n",
    "Have you ever tried Java on AWS Lambda but found that the cold-start latency and memory usage were far too high? \n",
    "In this session, we will show how we optimized Java for serverless applications by leveraging GraalVM with Quarkus to \n",
    "provide both supersonic startup speed and a subatomic memory footprint.\"\"\",\n",
    "\n",
    "    \"\"\"We really appreciate your interest and wanted to let you know that we have received your application.\n",
    "There is strong competition for jobs at Intel, and we receive many applications. As a result, it may take some time to get back to you.\n",
    "Whether or not this position ends up being a fit, we will keep your information per data retention policies, \n",
    "so we can contact you for other positions that align to your experience and skill set.\n",
    "\"\"\",\n",
    "    \"\"\"Government agencies like the IRS will not contact you via email, phone or text message. If any legitimate government agency needs to contact you, they will usually do so via mail or certified letter.\"\"\",\n",
    "    \"\"\"Notifications involving money owed to you are enticing, aren’t they? “Our records show that you overpaid for (a product or service). Kindly supply your bank routing and account number to receive your refund.” Don’t fall for it.\"\"\",\n",
    "    \"\"\"Scams hiding under the guise of financial institutions like Bank of America, Wells Fargo and Chase have famously allowed scammers to steal tons of personal banking information from customers. \n",
    "\n",
    "Banks will only attempt to verify your identity if you’ve had recent transactions with them, like opening a new account. So if you get a random verification text from your bank, it’s probably fake.\n",
    "\n",
    "\"\"\",\n",
    "    \"\"\"With deliveries from Amazon and FedEx so commonplace now, a text message regarding a package or order would be easy to overlook. While shippers do send legitimate shipping update texts, they’ll never ask for personal information or money to complete a delivery.\"\"\",\n",
    "    \"\"\"Any text that attempts to verify your Apple ID or another technology account is suspicious. If you suspect your account is compromised, contact the company directly and change your passwords immediately.\"\"\",\n",
    "    \"\"\"You should treat any offer of “free” bitcoin the same as any other offer of free money – with high scrutiny. Scammers often use bitcoin as currency in blackmail scams that demand payment for withholding personal details the scammer claims to have about you.\"\"\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89929435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa3a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "151a6de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(massege):\n",
    "    d=getDoc(massege)\n",
    "    return cv.transform(d)\n",
    "masseges=preprocess(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4af71993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14x7284 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 254 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masseges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23c8515e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham',\n",
       "       'spam', 'ham', 'ham', 'spam', 'spam'], dtype='<U4')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnb.predict(masseges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83421a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
